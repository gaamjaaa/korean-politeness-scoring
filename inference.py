#!/usr/bin/env python3
"""
í•œêµ­ì–´ ê³µì†ë„ ì˜ˆì¸¡ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµëœ KoBERT ë©€í‹°íƒœìŠ¤í¬ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë¬¸ì¥ì˜ ê³µì†ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

import os
import sys
import argparse
import torch
import pandas as pd
import numpy as np
from transformers import AutoTokenizer
from typing import List, Dict, Union

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from src.model import MultitaskPolitenessModel


class PolitenessPredictor:
    """ê³µì†ë„ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, model_path: str, model_name: str = "monologg/kobert", device: str = 'auto'):
        self.device = self._setup_device(device)
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = MultitaskPolitenessModel(model_name=model_name)
        checkpoint = torch.load(model_path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # í”¼ì²˜ ì´ë¦„ ì •ì˜
        self.feature_names = [
            'feat_ending', 'feat_strat_cnt', 'feat_indirect', 
            'feat_command', 'feat_attack', 'feat_power', 'feat_distance'
        ]
        
        self.feature_descriptions = {
            'feat_ending': 'ì–´ë¯¸ (ì¡´ëŒ“ë§ vs ë°˜ë§)',
            'feat_strat_cnt': 'ì „ëµì  í‘œí˜„ (ê°„ì ‘í™”ë²•, ì™„ê³¡í‘œí˜„ ë“±)',
            'feat_indirect': 'ê°„ì ‘ì„± (ëŒë ¤ë§í•˜ê¸°)',
            'feat_command': 'ëª…ë ¹ì¡° (ê°•ìš”, ì§€ì‹œ)',
            'feat_attack': 'ê³µê²©ì„± (ë¹„ë‚œ, ëª¨ìš•)',
            'feat_power': 'ê¶Œë ¥ê±°ë¦¬ (ë†’ì„/ë‚®ì¶¤)',
            'feat_distance': 'ì‚¬íšŒì  ê±°ë¦¬ê°'
        }
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
        print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {self.device}")
    
    def _setup_device(self, device_arg: str) -> str:
        """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
        if device_arg == 'auto':
            return 'cuda' if torch.cuda.is_available() else 'cpu'
        return device_arg
    
    def predict_single(self, sentence: str, return_probabilities: bool = False) -> Dict:
        """ë‹¨ì¼ ë¬¸ì¥ ì˜ˆì¸¡"""
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            sentence,
            truncation=True,
            padding='max_length',
            max_length=256,
            return_tensors='pt'
        )
        
        input_ids = encoding['input_ids'].to(self.device)
        attention_mask = encoding['attention_mask'].to(self.device)
        
        # ì˜ˆì¸¡
        with torch.no_grad():
            outputs = self.model.get_feature_predictions(input_ids, attention_mask)
        
        # ê²°ê³¼ ì •ë¦¬
        result = {
            'sentence': sentence,
            'overall_score': float(outputs['score_prediction'][0]),
            'features': {}
        }
        
        # í”¼ì²˜ë³„ ì˜ˆì¸¡ê°’
        for i, feature_name in enumerate(self.feature_names):
            pred = int(outputs['feature_predictions'][i][0])
            result['features'][feature_name] = {
                'prediction': pred,
                'description': self.feature_descriptions[feature_name]
            }
            
            if return_probabilities:
                probs = outputs['feature_probabilities'][i][0].cpu().numpy()
                result['features'][feature_name]['probabilities'] = probs.tolist()
        
        return result
    
    def predict_batch(self, sentences: List[str], return_probabilities: bool = False) -> List[Dict]:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        results = []
        for sentence in sentences:
            result = self.predict_single(sentence, return_probabilities)
            results.append(result)
        return results
    
    def analyze_politeness(self, sentence: str) -> Dict:
        """ê³µì†ë„ ë¶„ì„ (í•´ì„ í¬í•¨)"""
        result = self.predict_single(sentence, return_probabilities=True)
        
        # ê³µì†ë„ í•´ì„
        overall_score = result['overall_score']
        if overall_score >= 1.5:
            politeness_level = "ë§¤ìš° ê³µì†í•¨"
        elif overall_score >= 0.5:
            politeness_level = "ê³µì†í•¨"
        elif overall_score >= -0.5:
            politeness_level = "ì¤‘ë¦½"
        elif overall_score >= -1.5:
            politeness_level = "ë‹¤ì†Œ ë¬´ë¡€í•¨"
        else:
            politeness_level = "ë§¤ìš° ë¬´ë¡€í•¨"
        
        # ì£¼ìš” ì˜í–¥ ìš”ì†Œ ë¶„ì„
        influential_features = []
        for feature_name, feature_data in result['features'].items():
            pred = feature_data['prediction']
            if pred >= 2:  # 2ì  ì´ìƒì¸ í”¼ì²˜ë“¤
                influential_features.append({
                    'feature': feature_name,
                    'description': feature_data['description'],
                    'score': pred,
                    'impact': 'positive' if pred == 3 else 'moderate'
                })
            elif pred <= -2:  # -2ì  ì´í•˜ì¸ í”¼ì²˜ë“¤ (ì‹¤ì œë¡œëŠ” 0ì ì´ ìµœì €)
                influential_features.append({
                    'feature': feature_name,
                    'description': feature_data['description'],
                    'score': pred,
                    'impact': 'negative'
                })
        
        analysis = {
            'sentence': sentence,
            'overall_score': overall_score,
            'politeness_level': politeness_level,
            'feature_analysis': result['features'],
            'influential_features': influential_features,
            'interpretation': self._generate_interpretation(result)
        }
        
        return analysis
    
    def _generate_interpretation(self, result: Dict) -> str:
        """ê²°ê³¼ í•´ì„ ìƒì„±"""
        sentence = result['sentence']
        score = result['overall_score']
        features = result['features']
        
        interpretation = f"ë¬¸ì¥ '{sentence}'ì˜ ê³µì†ë„ ë¶„ì„:\n\n"
        interpretation += f"ì „ì²´ ê³µì†ë„ ì ìˆ˜: {score:.2f}\n"
        
        # ë†’ì€ ì ìˆ˜ í”¼ì²˜ë“¤
        high_features = []
        low_features = []
        
        for fname, fdata in features.items():
            pred = fdata['prediction']
            if pred >= 2:
                high_features.append((fname, fdata['description'], pred))
            elif pred == 0:
                low_features.append((fname, fdata['description'], pred))
        
        if high_features:
            interpretation += "\nâœ… ê³µì†í•¨ì„ ë‚˜íƒ€ë‚´ëŠ” ìš”ì†Œë“¤:\n"
            for fname, desc, pred in high_features:
                interpretation += f"  - {desc}: {pred}ì \n"
        
        if low_features:
            interpretation += "\nâš ï¸ ê°œì„ ì´ í•„ìš”í•œ ìš”ì†Œë“¤:\n"
            for fname, desc, pred in low_features:
                interpretation += f"  - {desc}: {pred}ì \n"
        
        # ì¢…í•© ì˜ê²¬
        if score >= 1.0:
            interpretation += "\nğŸ’¬ ì „ë°˜ì ìœ¼ë¡œ ê³µì†í•˜ê³  ì˜ˆì˜ë°”ë¥¸ í‘œí˜„ì…ë‹ˆë‹¤."
        elif score >= 0:
            interpretation += "\nğŸ’¬ ì ì ˆí•œ ìˆ˜ì¤€ì˜ í‘œí˜„ì´ì§€ë§Œ, ìƒí™©ì— ë”°ë¼ ë” ê³µì†í•œ í‘œí˜„ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        else:
            interpretation += "\nğŸ’¬ ë‹¤ì†Œ ì§ì ‘ì ì´ê±°ë‚˜ ë¬´ë¡€í•  ìˆ˜ ìˆëŠ” í‘œí˜„ì…ë‹ˆë‹¤. ë” ê³µì†í•œ í‘œí˜„ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
        
        return interpretation


def parse_args():
    """ëª…ë ¹í–‰ ì¸ì íŒŒì‹±"""
    parser = argparse.ArgumentParser(description="í•œêµ­ì–´ ê³µì†ë„ ì˜ˆì¸¡ ì¶”ë¡ ")
    
    parser.add_argument('--model_path', type=str, required=True,
                       help='í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (.pt)')
    parser.add_argument('--sentence', type=str,
                       help='ë¶„ì„í•  ë‹¨ì¼ ë¬¸ì¥')
    parser.add_argument('--input_file', type=str,
                       help='ë¶„ì„í•  ë¬¸ì¥ë“¤ì´ ë‹´ê¸´ íŒŒì¼ (CSV, í…ìŠ¤íŠ¸)')
    parser.add_argument('--output_file', type=str,
                       help='ê²°ê³¼ ì €ì¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--model_name', type=str, default='monologg/kobert',
                       help='ì‚¬ìš©í•  KoBERT ëª¨ë¸ëª…')
    parser.add_argument('--device', type=str, default='auto',
                       help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (auto/cuda/cpu)')
    parser.add_argument('--detailed', action='store_true',
                       help='ìƒì„¸ ë¶„ì„ ëª¨ë“œ (í•´ì„ í¬í•¨)')
    parser.add_argument('--probabilities', action='store_true',
                       help='í™•ë¥ ê°’ í¬í•¨')
    
    return parser.parse_args()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_args()
    
    print("ğŸ¯ í•œêµ­ì–´ ê³µì†ë„ ì˜ˆì¸¡ ì¶”ë¡  ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    predictor = PolitenessPredictor(
        model_path=args.model_path,
        model_name=args.model_name,
        device=args.device
    )
    
    # ë‹¨ì¼ ë¬¸ì¥ ë¶„ì„
    if args.sentence:
        print(f"\nğŸ“ ë¬¸ì¥ ë¶„ì„: '{args.sentence}'")
        print("-" * 50)
        
        if args.detailed:
            analysis = predictor.analyze_politeness(args.sentence)
            print(analysis['interpretation'])
            
            if args.probabilities:
                print(f"\nğŸ“Š í”¼ì²˜ë³„ í™•ë¥  ë¶„í¬:")
                for fname, fdata in analysis['feature_analysis'].items():
                    if 'probabilities' in fdata:
                        probs = fdata['probabilities']
                        print(f"  {fdata['description']}: {probs}")
        else:
            result = predictor.predict_single(args.sentence, args.probabilities)
            print(f"ì „ì²´ ê³µì†ë„ ì ìˆ˜: {result['overall_score']:.3f}")
            print(f"\ní”¼ì²˜ë³„ ì˜ˆì¸¡:")
            for fname, fdata in result['features'].items():
                print(f"  {fdata['description']}: {fdata['prediction']}ì ")
    
    # íŒŒì¼ ë°°ì¹˜ ë¶„ì„
    elif args.input_file:
        print(f"\nğŸ“ íŒŒì¼ ë°°ì¹˜ ë¶„ì„: {args.input_file}")
        
        # íŒŒì¼ ì½ê¸°
        if args.input_file.endswith('.csv'):
            df = pd.read_csv(args.input_file)
            if 'sentence' in df.columns:
                sentences = df['sentence'].tolist()
            else:
                sentences = df.iloc[:, 0].tolist()  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
        else:
            # í…ìŠ¤íŠ¸ íŒŒì¼
            with open(args.input_file, 'r', encoding='utf-8') as f:
                sentences = [line.strip() for line in f if line.strip()]
        
        print(f"ë¶„ì„í•  ë¬¸ì¥ ìˆ˜: {len(sentences)}")
        
        # ë°°ì¹˜ ì˜ˆì¸¡
        if args.detailed:
            results = []
            for sentence in sentences:
                analysis = predictor.analyze_politeness(sentence)
                results.append(analysis)
        else:
            results = predictor.predict_batch(sentences, args.probabilities)
        
        # ê²°ê³¼ ì €ì¥
        if args.output_file:
            if args.output_file.endswith('.csv'):
                # CSV í˜•íƒœë¡œ ì €ì¥
                output_data = []
                for result in results:
                    row = {
                        'sentence': result['sentence'],
                        'overall_score': result['overall_score']
                    }
                    
                    if 'feature_analysis' in result:
                        features = result['feature_analysis']
                    else:
                        features = result['features']
                    
                    for fname, fdata in features.items():
                        row[fname] = fdata['prediction']
                    
                    if args.detailed and 'politeness_level' in result:
                        row['politeness_level'] = result['politeness_level']
                    
                    output_data.append(row)
                
                pd.DataFrame(output_data).to_csv(args.output_file, index=False, encoding='utf-8')
            else:
                # JSON í˜•íƒœë¡œ ì €ì¥
                import json
                with open(args.output_file, 'w', encoding='utf-8') as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {args.output_file}")
        
        # ìš”ì•½ í†µê³„
        scores = [r['overall_score'] for r in results]
        print(f"\nğŸ“Š ì „ì²´ ë¶„ì„ ìš”ì•½:")
        print(f"  í‰ê·  ê³µì†ë„: {np.mean(scores):.3f}")
        print(f"  í‘œì¤€í¸ì°¨: {np.std(scores):.3f}")
        print(f"  ìµœê³ ì : {np.max(scores):.3f}")
        print(f"  ìµœì €ì : {np.min(scores):.3f}")
    
    else:
        # ëŒ€í™”í˜• ëª¨ë“œ
        print(f"\nğŸ’¬ ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ (ì¢…ë£Œ: 'quit' ì…ë ¥)")
        print("-" * 50)
        
        while True:
            sentence = input("ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if sentence.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                break
            
            if not sentence:
                continue
            
            try:
                if args.detailed:
                    analysis = predictor.analyze_politeness(sentence)
                    print(f"\n{analysis['interpretation']}\n")
                else:
                    result = predictor.predict_single(sentence)
                    print(f"ê³µì†ë„ ì ìˆ˜: {result['overall_score']:.3f}")
                    print("í”¼ì²˜ë³„ ì ìˆ˜:", end=" ")
                    feature_scores = [str(fdata['prediction']) for fdata in result['features'].values()]
                    print(" | ".join(feature_scores))
                    print()
            
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\n")
    
    print("ğŸ¯ ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main() 