import torch
import numpy as np
import pandas as pd
from transformers import BertTokenizer
import matplotlib.pyplot as plt
import seaborn as sns
from multitask_model import ImprovedMultiTaskModel, KoPolitenessDataset

plt.rcParams['font.family'] = 'DejaVu Sans'  # í•œê¸€ í°íŠ¸ ì„¤ì •

class PolitenessAnalyzer:
    """ê³µì†ë„ ë¶„ì„ê¸°"""
    
    def __init__(self, model_path, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        self.tokenizer = BertTokenizer.from_pretrained(config['model_name'])
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.unk_token
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = ImprovedMultiTaskModel(
            model_name=config['model_name'],
            dropout_rate=config['dropout_rate']
        ).to(self.device)
        
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
        # í”¼ì²˜ ì´ë¦„ê³¼ ì„¤ëª… (í´ë˜ìŠ¤ 3 â†’ 2 ë³‘í•© ë°˜ì˜)
        self.feature_info = {
            'feat_ending': {
                'name': 'ì–´ë¯¸',
                'classes': ['ë°˜ë§/ë¹„ê²©ì‹', 'ê²©ì‹ì  ì–´ë¯¸', 'ì¡´ëŒ“ë§ (ìµœê³  ì¡´ëŒ“ë§ í¬í•¨)'],
                'description': 'ë¬¸ì¥ ì¢…ê²° ì–´ë¯¸ì˜ ê²©ì‹ë„'
            },
            'feat_strat_cnt': {
                'name': 'ì „ëµì  í‘œí˜„',
                'classes': ['ì—†ìŒ', 'ë‹¨ìˆœ ì™„í™”', 'ë³µí•© ì „ëµ'],
                'description': 'ê³µì† ì „ëµ í‘œí˜„ì˜ ë³µì¡ë„'
            },
            'feat_command': {
                'name': 'ëª…ë ¹ì„±',
                'classes': ['ì„œìˆ /ì§ˆë¬¸', 'ì œì•ˆ/ìš”ì²­', 'ì§€ì‹œ/ëª…ë ¹ (ê°•í•œ ëª…ë ¹ í¬í•¨)'],
                'description': 'í™”í–‰ì˜ ëª…ë ¹ì„± ì •ë„'
            },
            'feat_attack': {
                'name': 'ê³µê²©ì„±',
                'classes': ['ì¤‘ë¦½', 'ê°€ë²¼ìš´ ë¹„íŒ', 'ì§ì ‘ì  ë¹„íŒ (ê°•í•œ ê³µê²© í¬í•¨)'],
                'description': 'ì–¸ì–´ì  ê³µê²©ì„± ìˆ˜ì¤€'
            },
            'feat_power': {
                'name': 'ê¶Œë ¥ê±°ë¦¬',
                'classes': ['ë™ë“±', 'ì•½ê°„ ìƒí•˜ê´€ê³„', 'ëª…í™•í•œ ìƒí•˜ê´€ê³„ (ê°•í•œ ê¶Œë ¥ê´€ê³„ í¬í•¨)'],
                'description': 'í™”ìì™€ ì²­ì ê°„ ê¶Œë ¥ ê´€ê³„'
            },
            'feat_distance': {
                'name': 'ì‚¬íšŒì  ê±°ë¦¬',
                'classes': ['ê°€ê¹Œì›€', 'ë³´í†µ', 'ê²©ì‹ì  (ë§¤ìš° ê²©ì‹ì  í¬í•¨)'],
                'description': 'í™”ìì™€ ì²­ì ê°„ ì‚¬íšŒì  ê±°ë¦¬'
            },
            'feat_indirect': {
                'name': 'ê°„ì ‘ì„±',
                'classes': ['ì§ì ‘ì ', 'ì•½ê°„ ê°„ì ‘ì ', 'ë§¤ìš° ê°„ì ‘ì '],
                'description': 'í‘œí˜„ì˜ ê°„ì ‘ì„± ì •ë„'
            }
        }
        
        print(f"ğŸš€ PolitenessAnalyzer loaded on {self.device}")
    
    def predict_single(self, sentence):
        """ë‹¨ì¼ ë¬¸ì¥ ì˜ˆì¸¡"""
        # í† í¬ë‚˜ì´ì§•
        encoded = self.tokenizer(
            sentence,
            truncation=True,
            padding='max_length',
            max_length=self.config['max_length'],
            return_tensors='pt'
        )
        
        input_ids = encoded['input_ids'].to(self.device)
        attention_mask = encoded['attention_mask'].to(self.device)
        
        with torch.no_grad():
            feature_logits, score_pred = self.model(input_ids, attention_mask)
        
        # í”¼ì²˜ë³„ ì˜ˆì¸¡
        feature_preds = {}
        feature_probs = {}
        
        for feat_name, logits in feature_logits.items():
            probs = torch.softmax(logits, dim=-1)
            pred_class = torch.argmax(logits, dim=-1).item()
            
            feature_preds[feat_name] = pred_class
            feature_probs[feat_name] = probs.cpu().numpy()[0]
        
        # ìŠ¤ì½”ì–´ ì˜ˆì¸¡ (ì •ê·œí™” í•´ì œ)
        if self.config.get('normalize_scores', True):
            score = score_pred.item() * 6.0 - 3.0
        else:
            score = score_pred.item()
        
        return {
            'sentence': sentence,
            'predicted_score': score,
            'feature_predictions': feature_preds,
            'feature_probabilities': feature_probs
        }
    
    def predict_batch(self, sentences):
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        results = []
        for sentence in sentences:
            result = self.predict_single(sentence)
            results.append(result)
        return results
    
    def analyze_politeness(self, sentence, show_details=True):
        """ê³µì†ë„ ìƒì„¸ ë¶„ì„"""
        result = self.predict_single(sentence)
        
        print(f"ğŸ“ ë¬¸ì¥: {sentence}")
        print(f"ğŸ¯ ì˜ˆì¸¡ ê³µì†ë„ ì ìˆ˜: {result['predicted_score']:.2f} (-3: ë§¤ìš° ë¬´ë¡€ ~ +3: ë§¤ìš° ê³µì†)")
        
        # ì ìˆ˜ í•´ì„
        score = result['predicted_score']
        if score >= 2.0:
            interpretation = "ë§¤ìš° ê³µì†í•œ í‘œí˜„"
        elif score >= 1.0:
            interpretation = "ê³µì†í•œ í‘œí˜„"
        elif score >= -0.5:
            interpretation = "ì¤‘ë¦½ì  í‘œí˜„"
        elif score >= -1.5:
            interpretation = "ë‹¤ì†Œ ë¬´ë¡€í•œ í‘œí˜„"
        else:
            interpretation = "ë§¤ìš° ë¬´ë¡€í•œ í‘œí˜„"
        
        print(f"ğŸ” í•´ì„: {interpretation}")
        
        if show_details:
            print("\nğŸ“Š í”¼ì²˜ë³„ ë¶„ì„:")
            for feat_name, pred_class in result['feature_predictions'].items():
                info = self.feature_info[feat_name]
                class_name = info['classes'][pred_class]
                confidence = result['feature_probabilities'][feat_name][pred_class]
                
                print(f"  {info['name']}: {class_name} (í™•ì‹ ë„: {confidence:.2f})")
                print(f"    â†’ {info['description']}")
        
        return result
    
    def compare_sentences(self, sentences, labels=None):
        """ì—¬ëŸ¬ ë¬¸ì¥ ë¹„êµ ë¶„ì„"""
        results = self.predict_batch(sentences)
        
        if labels is None:
            labels = [f"ë¬¸ì¥ {i+1}" for i in range(len(sentences))]
        
        # ê²°ê³¼ ì‹œê°í™”
        scores = [r['predicted_score'] for r in results]
        
        plt.figure(figsize=(12, 6))
        
        # ì ìˆ˜ ë¹„êµ
        plt.subplot(1, 2, 1)
        bars = plt.bar(labels, scores)
        plt.title('ê³µì†ë„ ì ìˆ˜ ë¹„êµ')
        plt.ylabel('ê³µì†ë„ ì ìˆ˜')
        plt.xticks(rotation=45)
        plt.axhline(y=0, color='r', linestyle='--', alpha=0.5)
        
        # ìƒ‰ìƒ ì„¤ì •
        for i, (bar, score) in enumerate(zip(bars, scores)):
            if score >= 1.0:
                bar.set_color('green')
            elif score >= -0.5:
                bar.set_color('yellow')
            else:
                bar.set_color('red')
        
        # í”¼ì²˜ë³„ íˆíŠ¸ë§µ
        plt.subplot(1, 2, 2)
        feature_matrix = []
        feature_names = list(self.feature_info.keys())
        
        for result in results:
            row = [result['feature_predictions'][feat] for feat in feature_names]
            feature_matrix.append(row)
        
        sns.heatmap(
            feature_matrix,
            xticklabels=[self.feature_info[f]['name'] for f in feature_names],
            yticklabels=labels,
            annot=True,
            fmt='d',
            cmap='RdYlGn',
            cbar_kws={'label': 'í´ë˜ìŠ¤ (ë†’ì„ìˆ˜ë¡ ê³µì†)'}
        )
        plt.title('í”¼ì²˜ë³„ ì˜ˆì¸¡ ê²°ê³¼')
        
        plt.tight_layout()
        plt.show()
        
        return results
    
    def feature_importance_analysis(self, sentence):
        """í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„ (ê°„ë‹¨í•œ perturbation ê¸°ë°˜)"""
        original_result = self.predict_single(sentence)
        original_score = original_result['predicted_score']
        
        print(f"ğŸ“ ì›ë³¸ ë¬¸ì¥: {sentence}")
        print(f"ğŸ¯ ì›ë³¸ ì ìˆ˜: {original_score:.2f}")
        print("\nğŸ” í”¼ì²˜ ì œê±° ì‹¤í—˜:")
        
        # ê° í”¼ì²˜ì˜ ê¸°ì—¬ë„ ë¶„ì„ (ë‹¨ìˆœí™”ëœ ë°©ë²•)
        feature_contributions = {}
        
        for feat_name in self.feature_info.keys():
            # í•´ë‹¹ í”¼ì²˜ì˜ ì˜ˆì¸¡ê°’ì„ 0(ì¤‘ë¦½)ìœ¼ë¡œ ê°•ì œ ì„¤ì •í•˜ê³  ì¬ì˜ˆì¸¡
            # ì‹¤ì œë¡œëŠ” ëª¨ë¸ì„ ìˆ˜ì •í•´ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°œë…ì  ì„¤ëª…
            pred_class = original_result['feature_predictions'][feat_name]
            info = self.feature_info[feat_name]
            
            # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ì˜ "ê¸°ì—¬ë„" ì¶”ì •
            contribution = (pred_class - 1.5) * 0.5  # ë‹¨ìˆœí™”ëœ ê³„ì‚°
            feature_contributions[feat_name] = contribution
            
            print(f"  {info['name']}: {info['classes'][pred_class]} (ê¸°ì—¬ë„: {contribution:+.2f})")
        
        return feature_contributions
    
    def batch_analyze_csv(self, csv_path, sentence_col='sentence', output_path=None):
        """CSV íŒŒì¼ ì¼ê´„ ë¶„ì„"""
        df = pd.read_csv(csv_path)
        sentences = df[sentence_col].tolist()
        
        print(f"ğŸ“ {len(sentences)}ê°œ ë¬¸ì¥ ë¶„ì„ ì¤‘...")
        
        results = self.predict_batch(sentences)
        
        # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì •ë¦¬
        result_data = []
        for i, result in enumerate(results):
            row = {
                'sentence': result['sentence'],
                'predicted_score': result['predicted_score']
            }
            
            # í”¼ì²˜ë³„ ì˜ˆì¸¡ ì¶”ê°€
            for feat_name, pred_class in result['feature_predictions'].items():
                row[f'{feat_name}_pred'] = pred_class
                row[f'{feat_name}_class'] = self.feature_info[feat_name]['classes'][pred_class]
            
            result_data.append(row)
        
        result_df = pd.DataFrame(result_data)
        
        if output_path:
            result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        
        # ê¸°ë³¸ í†µê³„
        print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½:")
        print(f"í‰ê·  ê³µì†ë„: {result_df['predicted_score'].mean():.2f}")
        print(f"í‘œì¤€í¸ì°¨: {result_df['predicted_score'].std():.2f}")
        print(f"ìµœê³  ì ìˆ˜: {result_df['predicted_score'].max():.2f}")
        print(f"ìµœì € ì ìˆ˜: {result_df['predicted_score'].min():.2f}")
        
        return result_df
    
    def interactive_analysis(self):
        """ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ"""
        print("ğŸ¤– í•œêµ­ì–´ ê³µì†ë„ ë¶„ì„ê¸°ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
        print("ë¬¸ì¥ì„ ì…ë ¥í•˜ë©´ ê³µì†ë„ë¥¼ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤. (ì¢…ë£Œ: 'quit')")
        
        while True:
            sentence = input("\nğŸ“ ë¶„ì„í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if sentence.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ğŸ‘‹ ë¶„ì„ê¸°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            if not sentence:
                continue
            
            try:
                self.analyze_politeness(sentence)
                
                # ê°œì„  ì œì•ˆ
                result = self.predict_single(sentence)
                if result['predicted_score'] < 0:
                    print("\nğŸ’¡ ê°œì„  ì œì•ˆ:")
                    print("  - ì¡´ëŒ“ë§ ì‚¬ìš© ê³ ë ¤")
                    print("  - ê°„ì ‘ì  í‘œí˜„ ì‚¬ìš©")
                    print("  - ê³µì† í‘œí˜„ ì¶”ê°€ (ì˜ˆ: 'í˜¹ì‹œ', 'ë¶€íƒë“œë¦½ë‹ˆë‹¤')")
                
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

def demonstrate_analyzer():
    """ë¶„ì„ê¸° ì‹œì—°"""
    # ì„¤ì • (ì‹¤ì œ ì‚¬ìš© ì‹œ ìˆ˜ì • í•„ìš”)
    config = {
        'model_name': 'monologg/kobert',
        'max_length': 256,
        'dropout_rate': 0.3,
        'normalize_scores': True
    }
    
    # ì˜ˆì‹œ ë¬¸ì¥ë“¤
    test_sentences = [
        "ëˆˆì´ ì¢€ ì˜¤ë”êµ¬ë‚˜.",
        "ì•¼. ì§€ê¸ˆ ë°–ì— ì–´ë•Œ?",
        "ë³„ë§ì”€ì„ìš”. ê·¸ëŸ¼ ì˜¤ëŠ˜ í•˜ë£¨ë„ ì¦ê±°ìš´ ë§ˆìŒìœ¼ë¡œ ì‹œì‘í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.",
        "íšŒì˜ëŠ” ì˜ˆì •ëœ ì‹œê°„ì— ì‹œì‘ ë˜ë‹ˆ ì ì‹œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.",
        "ë‹¹ì‹ ì´ë‚˜ ì¢€ ì˜í•˜ì„¸ìš”. ë‚¨ ì‹ ê²½ ì“°ì§€ ë§ˆì‹œê³ ."
    ]
    
    print("ğŸ¯ í•œêµ­ì–´ ê³µì†ë„ ë¶„ì„ ì‹œì—°")
    print("=" * 50)
    
    # ëª¨ë¸ ê²½ë¡œë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤
    model_path = "./results/best_model_fold_0.pt"
    
    try:
        analyzer = PolitenessAnalyzer(model_path, config)
        
        print("\nğŸ“Š ë‹¤ì–‘í•œ ë¬¸ì¥ì˜ ê³µì†ë„ ë¹„êµ:")
        analyzer.compare_sentences(test_sentences)
        
        print("\nğŸ” ê°œë³„ ë¬¸ì¥ ìƒì„¸ ë¶„ì„:")
        for sentence in test_sentences[:2]:  # ì²˜ìŒ 2ê°œë§Œ ìƒì„¸ ë¶„ì„
            print("\n" + "="*50)
            analyzer.analyze_politeness(sentence)
            
    except FileNotFoundError:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € train_multitask.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    demonstrate_analyzer() 