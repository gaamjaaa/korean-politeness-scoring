import os
import json
import numpy as np
import pandas as pd
import torch
import torch.optim as optim
from torch.utils.data import DataLoader
from transformers import BertTokenizer, get_linear_schedule_with_warmup
from sklearn.metrics import classification_report, confusion_matrix, f1_score, cohen_kappa_score
from sklearn.model_selection import StratifiedKFold
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

from multitask_model import (
    KoPolitenessDataset, ImprovedMultiTaskModel, compute_multitask_loss,
    compute_class_weights, smart_train_val_split, forced_kfold_split
)

class MultitaskTrainer:
    def __init__(self, config):
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ Using device: {self.device}")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        self.tokenizer = BertTokenizer.from_pretrained(config['model_name'])
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.unk_token
        
        # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        os.makedirs(config['save_dir'], exist_ok=True)
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("ğŸ“ Loading data...")
        
        # Manual ë°ì´í„° ë¡œë“œ
        manual_df = pd.read_csv(self.config['manual_data_path'])
        print(f"Manual data: {len(manual_df)} samples")
        
        # TyDiP ë°ì´í„° ë¡œë“œ
        tydip_df = pd.read_csv(self.config['tydip_data_path'])
        print(f"TyDiP data: {len(tydip_df)} samples")
        
        # ìŠ¤ì½”ì–´ ì •ê·œí™” (ì„ íƒì )
        if self.config.get('normalize_scores', True):
            manual_df['score_normalized'] = (manual_df['score'] + 3.0) / 6.0
            tydip_df['score_normalized'] = (tydip_df['score'] + 3.0) / 6.0
            score_col = 'score_normalized'
        else:
            score_col = 'score'
        
        self.manual_df = manual_df
        self.tydip_df = tydip_df
        self.score_col = score_col
        
        # í”¼ì²˜ ë¶„í¬ ì¶œë ¥
        self.print_feature_distribution()
        
    def print_feature_distribution(self):
        """í”¼ì²˜ë³„ í´ë˜ìŠ¤ ë¶„í¬ ì¶œë ¥"""
        print("\nğŸ“Š Feature distribution analysis:")
        feature_cols = [
            "feat_ending", "feat_strat_cnt", "feat_command",
            "feat_attack", "feat_power", "feat_distance", "feat_indirect"
        ]
        
        for col in feature_cols:
            counts = self.manual_df[col].value_counts().sort_index()
            print(f"{col}: {dict(counts)}")
            
            # í¬ê·€ í´ë˜ìŠ¤ ê²½ê³ 
            rare_classes = counts[counts < 10].index.tolist()
            if rare_classes:
                print(f"Rare classes (< 10 samples): {rare_classes}")
        print()
    
    def compute_class_weights_all_features(self, train_df):
        """ëª¨ë“  í”¼ì²˜ì— ëŒ€í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
        feature_cols = [
            "feat_ending", "feat_strat_cnt", "feat_command",
            "feat_attack", "feat_power", "feat_distance", "feat_indirect"
        ]
        
        class_weights_dict = {}
        
        for col in feature_cols:
            labels = train_df[col].values
            # ì—…ë°ì´íŠ¸ëœ í´ë˜ìŠ¤ ìˆ˜ ì‚¬ìš©
            num_classes = FEATURE_CONFIGS[col]
            
            weights = compute_class_weights(labels, num_classes, feature_name=col)
            class_weights_dict[col] = weights.to(self.device)
            
            print(f"Class weights for {col}: {weights.numpy()}")
        
        return class_weights_dict
    
    def create_dataloaders(self, train_indices, val_indices, manual_df, tydip_df):
        """ë°ì´í„°ë¡œë” ìƒì„± (í›ˆë ¨ìš©)"""
        # Manual train/val split
        manual_train = manual_df.iloc[train_indices].copy()
        manual_val = manual_df.iloc[val_indices].copy()
        
        # TyDiP train/val split (ì¼ë°˜ì ì¸ split)
        tydip_train_size = int(len(tydip_df) * 0.8)
        tydip_train = tydip_df.iloc[:tydip_train_size].copy()
        tydip_val = tydip_df.iloc[tydip_train_size:].copy()
        
        # í”¼ì²˜ ë¼ë²¨ ì¶”ì¶œ (Manualë§Œ)
        feature_cols = [
            "feat_ending", "feat_strat_cnt", "feat_command",
            "feat_attack", "feat_power", "feat_distance", "feat_indirect"
        ]
        
        manual_train_features = manual_train[feature_cols].values
        manual_val_features = manual_val[feature_cols].values
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_manual_dataset = KoPolitenessDataset(
            sentences=manual_train['sentence'].tolist(),
            feat_labels=manual_train_features,
            scores=manual_train[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        train_tydip_dataset = KoPolitenessDataset(
            sentences=tydip_train['sentence'].tolist(),
            feat_labels=None,  # TyDiPëŠ” í”¼ì²˜ ë¼ë²¨ ì—†ìŒ
            scores=tydip_train[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        val_manual_dataset = KoPolitenessDataset(
            sentences=manual_val['sentence'].tolist(),
            feat_labels=manual_val_features,
            scores=manual_val[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        val_tydip_dataset = KoPolitenessDataset(
            sentences=tydip_val['sentence'].tolist(),
            feat_labels=None,
            scores=tydip_val[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_manual_loader = DataLoader(
            train_manual_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=True,
            num_workers=0
        )
        
        train_tydip_loader = DataLoader(
            train_tydip_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=True,
            num_workers=0
        )
        
        val_manual_loader = DataLoader(
            val_manual_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=False,
            num_workers=0
        )
        
        val_tydip_loader = DataLoader(
            val_tydip_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=False,
            num_workers=0
        )
        
        return {
            'train_manual': train_manual_loader,
            'train_tydip': train_tydip_loader,
            'val_manual': val_manual_loader,
            'val_tydip': val_tydip_loader
        }, manual_train
    
    def create_validation_dataloaders(self, val_indices, manual_df, tydip_df):
        """Validation ì „ìš© ë°ì´í„°ë¡œë” ìƒì„±"""
        # Manual val split
        manual_val = manual_df.iloc[val_indices].copy()
        
        # TyDiP val split
        tydip_train_size = int(len(tydip_df) * 0.8)
        tydip_val = tydip_df.iloc[tydip_train_size:].copy()
        
        # í”¼ì²˜ ë¼ë²¨ ì¶”ì¶œ
        feature_cols = [
            "feat_ending", "feat_strat_cnt", "feat_command",
            "feat_attack", "feat_power", "feat_distance", "feat_indirect"
        ]
        
        manual_val_features = manual_val[feature_cols].values
        
        # Validation ë°ì´í„°ì…‹ ìƒì„±
        val_manual_dataset = KoPolitenessDataset(
            sentences=manual_val['sentence'].tolist(),
            feat_labels=manual_val_features,
            scores=manual_val[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        val_tydip_dataset = KoPolitenessDataset(
            sentences=tydip_val['sentence'].tolist(),
            feat_labels=None,
            scores=tydip_val[self.score_col].tolist(),
            tokenizer=self.tokenizer,
            max_length=self.config['max_length']
        )
        
        # Validation ë°ì´í„°ë¡œë” ìƒì„±
        val_manual_loader = DataLoader(
            val_manual_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=False,
            num_workers=0
        )
        
        val_tydip_loader = DataLoader(
            val_tydip_dataset, 
            batch_size=self.config['batch_size'], 
            shuffle=False,
            num_workers=0
        )
        
        return {
            'val_manual': val_manual_loader,
            'val_tydip': val_tydip_loader
        }
    
    def train_epoch(self, model, train_loaders, optimizer, scheduler, class_weights_dict):
        """í•œ ì—í¬í¬ í›ˆë ¨ (ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  í¬í•¨)"""
        model.train()
        total_loss = 0.0
        num_batches = 0
        accumulation_steps = self.config.get('accumulation_steps', 1)
        
        print(f"ğŸ”§ ë°°ì¹˜ í¬ê¸°: {self.config['batch_size']}, ëˆ„ì  ë‹¨ê³„: {accumulation_steps}, íš¨ê³¼ì  ë°°ì¹˜: {self.config['batch_size'] * accumulation_steps}")
        
        # Manual ë°ì´í„°ë¡œ í›ˆë ¨
        for batch_idx, batch in enumerate(tqdm(train_loaders['train_manual'], desc="Training Manual")):
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            feat_labels = batch['feat_labels'].to(self.device)
            feat_mask = batch['feat_mask'].to(self.device)
            score_labels = batch['score'].to(self.device)
            score_mask = batch['score_mask'].to(self.device)
            
            # Forward pass
            feature_logits, score_pred = model(input_ids, attention_mask)
            
            # Loss ê³„ì‚°
            loss = compute_multitask_loss(
                feature_logits, score_pred, feat_labels, score_labels,
                feat_mask, score_mask, class_weights_dict, 
                use_focal=self.config.get('use_focal_loss', True),
                alpha=self.config['focal_alpha'],
                gamma=self.config['focal_gamma']
            )
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì ì„ ìœ„í•œ loss ì •ê·œí™”
            loss = loss / accumulation_steps
            
            # Backward pass
            loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  í›„ ì—…ë°ì´íŠ¸
            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loaders['train_manual']):
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            
            total_loss += loss.item() * accumulation_steps  # ì›ë˜ loss í¬ê¸°ë¡œ ë³µì›
            num_batches += 1
        
        # TyDiP ë°ì´í„°ë¡œ í›ˆë ¨ (ìŠ¤ì½”ì–´ë§Œ) - ë™ì¼í•œ ëˆ„ì  ë°©ì‹
        for batch_idx, batch in enumerate(tqdm(train_loaders['train_tydip'], desc="Training TyDiP")):
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            feat_labels = batch['feat_labels'].to(self.device)
            feat_mask = batch['feat_mask'].to(self.device)
            score_labels = batch['score'].to(self.device)
            score_mask = batch['score_mask'].to(self.device)
            
            # Forward pass
            feature_logits, score_pred = model(input_ids, attention_mask)
            
            # Loss ê³„ì‚° (ìŠ¤ì½”ì–´ë§Œ)
            loss = compute_multitask_loss(
                feature_logits, score_pred, feat_labels, score_labels,
                feat_mask, score_mask, class_weights_dict, 
                use_focal=self.config.get('use_focal_loss', True),
                alpha=self.config['focal_alpha'],
                gamma=self.config['focal_gamma']
            )
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì ì„ ìœ„í•œ loss ì •ê·œí™”
            loss = loss / accumulation_steps
            
            # Backward pass
            loss.backward()
            
            # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  í›„ ì—…ë°ì´íŠ¸
            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loaders['train_tydip']):
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                optimizer.step()
                scheduler.step()
                optimizer.zero_grad()
            
            total_loss += loss.item() * accumulation_steps  # ì›ë˜ loss í¬ê¸°ë¡œ ë³µì›
            num_batches += 1
        
        return total_loss / num_batches if num_batches > 0 else 0.0
    
    def evaluate(self, model, val_loaders):
        """ëª¨ë¸ í‰ê°€"""
        model.eval()
        results = {}
        
        with torch.no_grad():
            # Manual validation
            manual_results = self.evaluate_manual(model, val_loaders['val_manual'])
            results['manual'] = manual_results
            
            # TyDiP validation
            tydip_results = self.evaluate_tydip(model, val_loaders['val_tydip'])
            results['tydip'] = tydip_results
        
        return results
    
    def evaluate_manual(self, model, val_loader):
        """Manual ë°ì´í„° í‰ê°€ (í”¼ì²˜ë³„ ë¶„ë¥˜ + ìŠ¤ì½”ì–´ íšŒê·€)"""
        all_feature_preds = {name: [] for name in model.feature_heads.keys()}
        all_feature_labels = {name: [] for name in model.feature_heads.keys()}
        all_score_preds = []
        all_score_labels = []
        
        for batch in val_loader:
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            feat_labels = batch['feat_labels'].to(self.device)
            score_labels = batch['score'].to(self.device)
            
            feature_logits, score_pred = model(input_ids, attention_mask)
            
            # í”¼ì²˜ë³„ ì˜ˆì¸¡ ìˆ˜ì§‘
            for i, feat_name in enumerate(model.feature_heads.keys()):
                preds = torch.argmax(feature_logits[feat_name], dim=-1)
                all_feature_preds[feat_name].extend(preds.cpu().numpy())
                all_feature_labels[feat_name].extend(feat_labels[:, i].cpu().numpy())
            
            # ìŠ¤ì½”ì–´ ì˜ˆì¸¡ ìˆ˜ì§‘
            all_score_preds.extend(score_pred.cpu().numpy())
            all_score_labels.extend(score_labels.cpu().numpy())
        
        # í”¼ì²˜ë³„ ì„±ëŠ¥ ê³„ì‚° (ìˆœì„œí˜• ì§€í‘œ ì‚¬ìš©)
        feature_metrics = {}
        for feat_name in model.feature_heads.keys():
            preds = np.array(all_feature_preds[feat_name])
            labels = np.array(all_feature_labels[feat_name])
            num_classes = FEATURE_CONFIGS[feat_name]
            
            # ìˆœì„œí˜• ë¶„ë¥˜ ì§€í‘œ ê³„ì‚°
            feature_metrics[feat_name] = self.compute_ordinal_metrics(
                labels, preds, num_classes, feat_name
            )
        
        # ìŠ¤ì½”ì–´ ì„±ëŠ¥ ê³„ì‚°
        score_preds = np.array(all_score_preds)
        score_labels = np.array(all_score_labels)
        score_mae = np.mean(np.abs(score_preds - score_labels))
        score_rmse = np.sqrt(np.mean((score_preds - score_labels) ** 2))
        
        return {
            'features': feature_metrics,
            'score': {
                'mae': score_mae,
                'rmse': score_rmse
            }
        }
    
    def evaluate_tydip(self, model, val_loader):
        """TyDiP ë°ì´í„° í‰ê°€ (ìŠ¤ì½”ì–´ë§Œ)"""
        all_score_preds = []
        all_score_labels = []
        
        for batch in val_loader:
            input_ids = batch['input_ids'].to(self.device)
            attention_mask = batch['attention_mask'].to(self.device)
            score_labels = batch['score'].to(self.device)
            
            _, score_pred = model(input_ids, attention_mask)
            
            all_score_preds.extend(score_pred.cpu().numpy())
            all_score_labels.extend(score_labels.cpu().numpy())
        
        score_preds = np.array(all_score_preds)
        score_labels = np.array(all_score_labels)
        score_mae = np.mean(np.abs(score_preds - score_labels))
        score_rmse = np.sqrt(np.mean((score_preds - score_labels) ** 2))
        
        return {
            'mae': score_mae,
            'rmse': score_rmse
        }
    
    def train_fold(self, fold, train_indices, val_indices):
        """ë‹¨ì¼ fold í›ˆë ¨"""
        print(f"\nğŸš€ Starting fold {fold + 1}")
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        dataloaders, manual_train = self.create_dataloaders(
            train_indices, val_indices, self.manual_df, self.tydip_df
        )
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        class_weights_dict = self.compute_class_weights_all_features(manual_train)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = ImprovedMultiTaskModel(
            model_name=self.config['model_name'],
            dropout_rate=self.config['dropout_rate']
        ).to(self.device)
        
        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
        total_steps = (len(dataloaders['train_manual']) + len(dataloaders['train_tydip'])) * self.config['num_epochs']
        
        optimizer = optim.AdamW(
            model.parameters(),
            lr=self.config['learning_rate'],
            weight_decay=self.config['weight_decay'],
            eps=1e-8,
            betas=(0.9, 0.999)
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì„ íƒ
        if self.config.get('scheduler_type', 'linear') == 'cosine':
            from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts
            scheduler = CosineAnnealingWarmRestarts(
                optimizer,
                T_0=total_steps // 4,  # ì£¼ê¸°ë¥¼ 4ë“±ë¶„
                T_mult=1,
                eta_min=self.config['learning_rate'] * 0.01
            )
        else:
            scheduler = get_linear_schedule_with_warmup(
                optimizer,
                num_warmup_steps=int(total_steps * self.config['warmup_ratio']),
                num_training_steps=total_steps
            )
        
        # í›ˆë ¨ ë£¨í”„
        best_quad_kappa = 0.0  # Quadratic Weighted Kappaë¥¼ ë©”ì¸ ì§€í‘œë¡œ ë³€ê²½
        patience_counter = 0
        
        for epoch in range(self.config['num_epochs']):
            print(f"\nEpoch {epoch + 1}/{self.config['num_epochs']}")
            
            # í›ˆë ¨
            train_loss = self.train_epoch(model, dataloaders, optimizer, scheduler, class_weights_dict)
            
            # í‰ê°€
            eval_results = self.evaluate(model, dataloaders)
            
            # í˜„ì¬ ì„±ëŠ¥ ì¶œë ¥ (í•™ìˆ ì  ì§€í‘œ ì¤‘ì‹¬)
            quad_kappa_avg = np.mean([metrics['quad_kappa'] for metrics in eval_results['manual']['features'].values()])
            accuracy_avg = np.mean([metrics['accuracy'] for metrics in eval_results['manual']['features'].values()])
            adj_acc_avg = np.mean([metrics['adjacent_acc'] for metrics in eval_results['manual']['features'].values()])
            ordinal_mae_avg = np.mean([metrics['ordinal_mae'] for metrics in eval_results['manual']['features'].values()])
            
            manual_score_mae = eval_results['manual']['score']['mae']
            tydip_score_mae = eval_results['tydip']['mae']
            
            print(f"ğŸ”¥ Train Loss: {train_loss:.4f}")
            print(f"ğŸ“Š Quadratic Weighted Kappa: {quad_kappa_avg:.4f} (ë©”ì¸ ì§€í‘œ)")
            print(f"ğŸ“Š Accuracy: {accuracy_avg:.4f}, Adjacent Acc(Â±1): {adj_acc_avg:.4f}")
            print(f"ğŸ“Š Ordinal MAE: {ordinal_mae_avg:.4f}")
            print(f"ğŸ“Š Score MAE - Manual: {manual_score_mae:.4f}, TyDiP: {tydip_score_mae:.4f}")
            
            # Early stopping (Quadratic Weighted Kappa ê¸°ì¤€)
            if quad_kappa_avg > best_quad_kappa:
                best_quad_kappa = quad_kappa_avg
                patience_counter = 0
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'eval_results': eval_results,
                    'fold': fold,
                    'epoch': epoch
                }, f"{self.config['save_dir']}/best_model_fold_{fold}.pt")
                
                print(f"âœ¨ ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! Quadratic Kappa: {best_quad_kappa:.4f}")
                
            else:
                patience_counter += 1
                if patience_counter >= self.config['patience']:
                    print(f"â° Early stopping at epoch {epoch + 1}")
                    break
        
        return eval_results
    
    def run_kfold_training(self):
        """K-fold êµì°¨ê²€ì¦ ì‹¤í–‰ (ê°•ì œë°°ì¹˜ ë°©ì‹)"""
        print("ğŸ”„ Starting K-fold cross-validation with forced rare class allocation")
        
        # ìŠ¤ë§ˆíŠ¸ ë¶„í• ë¡œ ì „ì²´ validation ìƒì„±
        train_indices, val_indices = smart_train_val_split(
            self.manual_df, 
            test_size=0.2, 
            min_rare_samples=2,
            random_state=42
        )
        
        print(f"Initial split - Train: {len(train_indices)}, Val: {len(val_indices)}")
        
        # ê°•ì œë°°ì¹˜ K-foldë¥¼ train ë¶€ë¶„ì—ì„œ ìˆ˜í–‰
        train_df = self.manual_df.iloc[train_indices]
        folds = forced_kfold_split(train_df, n_folds=self.config['n_folds'], random_state=42)
        
        all_results = []
        
        for fold_idx, fold_val_indices in enumerate(folds):
            # ë‚˜ë¨¸ì§€ foldë“¤ì„ trainìœ¼ë¡œ ì‚¬ìš©
            fold_train_indices = []
            for other_fold_idx, other_fold in enumerate(folds):
                if other_fold_idx != fold_idx:
                    fold_train_indices.extend(other_fold)
            
            # forced_kfold_splitì´ ë°˜í™˜í•˜ëŠ” ì¸ë±ìŠ¤ë“¤ì´ ì´ë¯¸ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì˜ ì ˆëŒ€ ì¸ë±ìŠ¤ì´ë¯€ë¡œ ì§ì ‘ ì‚¬ìš©
            # fold_train_indicesì™€ fold_val_indicesëŠ” ì´ë¯¸ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœ
            
            # fold í›ˆë ¨
            fold_results = self.train_fold(fold_idx, fold_train_indices, fold_val_indices)
            all_results.append(fold_results)
        
        # ìµœì¢… ê²°ê³¼ ì§‘ê³„
        self.aggregate_results(all_results)
        
        # ìµœì¢… í™€ë“œì•„ì›ƒ í…ŒìŠ¤íŠ¸
        print("\nğŸ¯ Final evaluation on hold-out validation set")
        self.final_evaluation(val_indices)
    
    def aggregate_results(self, all_results):
        """K-fold ê²°ê³¼ ì§‘ê³„ (ìˆœì„œí˜• ë¶„ë¥˜ ì§€í‘œ ì¤‘ì‹¬)"""
        print("\nğŸ“ === í•™ìˆ ì  ì„±ëŠ¥ í‰ê°€ ê²°ê³¼ ===")
        
        feature_names = list(all_results[0]['manual']['features'].keys())
        
        # 1. ë©”ì¸ ì§€í‘œ: Quadratic Weighted Kappa
        print("\nğŸŒŸ === Quadratic Weighted Kappa (ë©”ì¸ ì§€í‘œ) ===")
        for feat_name in feature_names:
            kappa_scores = [result['manual']['features'][feat_name]['quad_kappa'] for result in all_results]
            print(f"{feat_name}: {np.mean(kappa_scores):.3f} Â± {np.std(kappa_scores):.3f}")
        
        # ì „ì²´ í‰ê·  Quadratic Kappa
        all_kappa_scores = []
        for result in all_results:
            fold_kappa = np.mean([metrics['quad_kappa'] for metrics in result['manual']['features'].values()])
            all_kappa_scores.append(fold_kappa)
        print(f"ğŸ“Š Overall Avg Quadratic Kappa: {np.mean(all_kappa_scores):.3f} Â± {np.std(all_kappa_scores):.3f}")
        
        # 2. ë³´ì¡° ì§€í‘œë“¤
        print("\nğŸ“ˆ === ë³´ì¡° ìˆœì„œí˜• ì§€í‘œë“¤ ===")
        
        # Adjacent Accuracy (Â±1 í—ˆìš©)
        all_adj_acc_scores = []
        for result in all_results:
            fold_adj_acc = np.mean([metrics['adjacent_acc'] for metrics in result['manual']['features'].values()])
            all_adj_acc_scores.append(fold_adj_acc)
        print(f"Adjacent Accuracy (Â±1): {np.mean(all_adj_acc_scores):.3f} Â± {np.std(all_adj_acc_scores):.3f}")
        
        # Ordinal MAE
        all_ordinal_mae_scores = []
        for result in all_results:
            fold_ordinal_mae = np.mean([metrics['ordinal_mae'] for metrics in result['manual']['features'].values()])
            all_ordinal_mae_scores.append(fold_ordinal_mae)
        print(f"Ordinal MAE: {np.mean(all_ordinal_mae_scores):.3f} Â± {np.std(all_ordinal_mae_scores):.3f}")
        
        # 3. ì „í†µì  ì§€í‘œë“¤ (ì°¸ê³ ìš©)
        print("\nğŸ“š === ì „í†µì  ë¶„ë¥˜ ì§€í‘œ (ì°¸ê³ ìš©) ===")
        
        # Accuracy
        all_accuracy_scores = []
        for result in all_results:
            fold_accuracy = np.mean([metrics['accuracy'] for metrics in result['manual']['features'].values()])
            all_accuracy_scores.append(fold_accuracy)
        print(f"Accuracy: {np.mean(all_accuracy_scores):.3f} Â± {np.std(all_accuracy_scores):.3f}")
        
        # F1 Scores
        all_f1_macro_scores = []
        all_f1_weighted_scores = []
        for result in all_results:
            fold_f1_macro = np.mean([metrics['f1_macro'] for metrics in result['manual']['features'].values()])
            fold_f1_weighted = np.mean([metrics['f1_weighted'] for metrics in result['manual']['features'].values()])
            all_f1_macro_scores.append(fold_f1_macro)
            all_f1_weighted_scores.append(fold_f1_weighted)
        
        print(f"F1 Macro: {np.mean(all_f1_macro_scores):.3f} Â± {np.std(all_f1_macro_scores):.3f}")
        print(f"F1 Weighted: {np.mean(all_f1_weighted_scores):.3f} Â± {np.std(all_f1_weighted_scores):.3f}")
        
        # 4. ìµœì¢… ìŠ¤ì½”ì–´ ì„±ëŠ¥
        print("\nğŸ¯ === ìµœì¢… ê³µì†ë„ ìŠ¤ì½”ì–´ ì„±ëŠ¥ ===")
        manual_maes = [result['manual']['score']['mae'] for result in all_results]
        tydip_maes = [result['tydip']['mae'] for result in all_results]
        
        print(f"Manual Score MAE: {np.mean(manual_maes):.3f} Â± {np.std(manual_maes):.3f}")
        print(f"TyDiP Score MAE: {np.mean(tydip_maes):.3f} Â± {np.std(tydip_maes):.3f}")
        
        # 5. êµìˆ˜ë‹˜ê»˜ ë³´ê³ í•  í•µì‹¬ ìš”ì•½
        print(f"\nğŸ“ === êµìˆ˜ë‹˜ ë³´ê³ ìš© í•µì‹¬ ìš”ì•½ ===")
        print(f"âœ¨ Quadratic Weighted Kappa: {np.mean(all_kappa_scores):.3f} (ìˆœì„œí˜• ë¶„ë¥˜ í‘œì¤€ ì§€í‘œ)")
        print(f"âœ¨ Adjacent Accuracy (Â±1): {np.mean(all_adj_acc_scores):.3f} (ì‹¤ìš©ì  í—ˆìš© ì„±ëŠ¥)")  
        print(f"âœ¨ Final Score MAE: {np.mean(manual_maes):.3f}ì  (ì‹¤ì œ í™œìš© ê°€ëŠ¥ì„±)")
        print(f"âœ¨ í•´ì„: ê³µì†ë„ëŠ” ìˆœì„œí˜• ë³€ìˆ˜ë¡œ, 1ë‹¨ê³„ ì°¨ì´ëŠ” ì‹¤ìš©ì ìœ¼ë¡œ í—ˆìš© ê°€ëŠ¥í•œ ë²”ìœ„ì…ë‹ˆë‹¤.")
    
    def final_evaluation(self, val_indices):
        """ìµœì¢… í™€ë“œì•„ì›ƒ í‰ê°€ (Quadratic Weighted Kappa ê¸°ì¤€)"""
        # ê°€ì¥ ì¢‹ì€ fold ëª¨ë¸ ë¡œë“œ (Quadratic Kappa ê¸°ì¤€)
        best_model_path = None
        best_kappa = 0.0
        
        for fold in range(self.config['n_folds']):
            model_path = f"{self.config['save_dir']}/best_model_fold_{fold}.pt"
            if os.path.exists(model_path):
                checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
                avg_kappa = np.mean([metrics['quad_kappa'] for metrics in checkpoint['eval_results']['manual']['features'].values()])
                
                if avg_kappa > best_kappa:
                    best_kappa = avg_kappa
                    best_model_path = model_path
        
        if best_model_path:
            print(f"\nğŸ† Loading best model (Quadratic Kappa: {best_kappa:.4f})")
            
            # ìµœê³  ëª¨ë¸ë¡œ ìµœì¢… í‰ê°€
            model = ImprovedMultiTaskModel(
                model_name=self.config['model_name'],
                dropout_rate=self.config['dropout_rate']
            ).to(self.device)
            
            checkpoint = torch.load(best_model_path, map_location=self.device, weights_only=False)
            model.load_state_dict(checkpoint['model_state_dict'])
            
            # í™€ë“œì•„ì›ƒ validation í‰ê°€
            dataloaders = self.create_validation_dataloaders(
                val_indices, self.manual_df, self.tydip_df
            )
            
            final_results = self.evaluate(model, dataloaders)
            
            # í•™ìˆ ì  ê²°ê³¼ ì¶œë ¥
            print("\nğŸ¯ === ìµœì¢… í™€ë“œì•„ì›ƒ í‰ê°€ ê²°ê³¼ ===")
            quad_kappa_avg = np.mean([metrics['quad_kappa'] for metrics in final_results['manual']['features'].values()])
            accuracy_avg = np.mean([metrics['accuracy'] for metrics in final_results['manual']['features'].values()])
            adj_acc_avg = np.mean([metrics['adjacent_acc'] for metrics in final_results['manual']['features'].values()])
            ordinal_mae_avg = np.mean([metrics['ordinal_mae'] for metrics in final_results['manual']['features'].values()])
            f1_macro_avg = np.mean([metrics['f1_macro'] for metrics in final_results['manual']['features'].values()])
            f1_weighted_avg = np.mean([metrics['f1_weighted'] for metrics in final_results['manual']['features'].values()])
            
            print(f"ğŸŒŸ Quadratic Weighted Kappa: {quad_kappa_avg:.4f}")
            print(f"ğŸ“Š Adjacent Accuracy (Â±1): {adj_acc_avg:.4f}")
            print(f"ğŸ“Š Ordinal MAE: {ordinal_mae_avg:.4f}")
            print(f"ğŸ“Š Accuracy: {accuracy_avg:.4f}")
            print(f"ğŸ“Š F1 Macro: {f1_macro_avg:.4f}, F1 Weighted: {f1_weighted_avg:.4f}")
            print(f"ğŸ“Š Manual Score MAE: {final_results['manual']['score']['mae']:.4f}")
            print(f"ğŸ“Š TyDiP Score MAE: {final_results['tydip']['mae']:.4f}")
            
            # í”¼ì²˜ë³„ ìƒì„¸ ê²°ê³¼ (í•™ìˆ ì  í˜•íƒœ)
            print("\nğŸ“‹ === í”¼ì²˜ë³„ ìƒì„¸ ì„±ëŠ¥ ===")
            for feat_name, metrics in final_results['manual']['features'].items():
                print(f"{feat_name}:")
                print(f"  Quadratic Kappa: {metrics['quad_kappa']:.3f}")
                print(f"  Adjacent Acc: {metrics['adjacent_acc']:.3f}")
                print(f"  Accuracy: {metrics['accuracy']:.3f}")
                print(f"  F1 Macro: {metrics['f1_macro']:.3f}")
            
            # ìµœì¢… êµìˆ˜ë‹˜ ë³´ê³ ìš© ìš”ì•½
            print(f"\nğŸ“ === ë…¼ë¬¸/ë³´ê³ ì„œìš© ìµœì¢… ìš”ì•½ ===")
            print(f"\"ê³µì†ë„ í”¼ì²˜ ë¶„ë¥˜ì—ì„œ Quadratic Weighted Kappa {quad_kappa_avg:.3f}ì„ ë‹¬ì„±í•˜ì—¬")
            print(f"ìˆœì„œí˜• ë¶„ë¥˜ ê´€ì ì—ì„œ ì–‘í˜¸í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.")
            print(f"íŠ¹íˆ Â±1 í—ˆìš© ì •í™•ë„ {adj_acc_avg:.3f}ê³¼ ìµœì¢… ìŠ¤ì½”ì–´ MAE {final_results['manual']['score']['mae']:.3f}ì ìœ¼ë¡œ")
            print(f"ì‹¤ìš©ì  í™œìš©ì´ ì¶©ë¶„íˆ ê°€ëŠ¥í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤.\"")
            
            return final_results
    
    def quadratic_weighted_kappa(self, y_true, y_pred, num_classes):
        """Quadratic Weighted Kappa for ordinal classification"""
        # Confusion matrix
        conf_mat = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))
        
        # Weight matrix (quadratic weights for ordinal data)
        weights = np.zeros((num_classes, num_classes))
        for i in range(num_classes):
            for j in range(num_classes):
                weights[i, j] = (i - j) ** 2
        
        # Normalize weights
        weights = weights / (num_classes - 1) ** 2
        
        # Expected confusion matrix (random chance)
        row_sums = conf_mat.sum(axis=1)
        col_sums = conf_mat.sum(axis=0)
        expected = np.outer(row_sums, col_sums) / conf_mat.sum()
        
        # Quadratic weighted kappa
        observed_agreement = np.sum(conf_mat * (1 - weights))
        expected_agreement = np.sum(expected * (1 - weights))
        
        if expected_agreement == 0:
            return 0.0
        
        kappa = (observed_agreement - expected_agreement) / (conf_mat.sum() - expected_agreement)
        return kappa
    
    def adjacent_accuracy(self, y_true, y_pred, tolerance=1):
        """Adjacent Accuracy: allows Â±tolerance error"""
        return np.mean(np.abs(y_true - y_pred) <= tolerance)
    
    def ordinal_mae(self, y_true, y_pred):
        """Mean Absolute Error for ordinal data (same as regular MAE)"""
        return np.mean(np.abs(y_true - y_pred))
    
    def compute_ordinal_metrics(self, y_true, y_pred, num_classes, feature_name):
        """Compute comprehensive ordinal classification metrics"""
        # Convert to numpy arrays
        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        
        # Basic metrics
        accuracy = (y_true == y_pred).mean()
        f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
        f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)
        
        # Ordinal-specific metrics
        try:
            quad_kappa = self.quadratic_weighted_kappa(y_true, y_pred, num_classes)
        except:
            quad_kappa = 0.0
            
        try:
            linear_kappa = cohen_kappa_score(y_true, y_pred, weights='linear')
        except:
            linear_kappa = 0.0
            
        adj_acc_1 = self.adjacent_accuracy(y_true, y_pred, tolerance=1)
        ordinal_mae = self.ordinal_mae(y_true, y_pred)
        
        return {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted,
            'quad_kappa': quad_kappa,      # ğŸŒŸ ë©”ì¸ ì§€í‘œ
            'linear_kappa': linear_kappa,
            'adjacent_acc': adj_acc_1,     # Â±1 í—ˆìš© ì •í™•ë„
            'ordinal_mae': ordinal_mae     # ìˆœì„œ ê±°ë¦¬ MAE
        }

# ì„¤ì •
config = {
    'model_name': 'monologg/kobert',
    'max_length': 256,
    'batch_size': 8,      # 12 â†’ 8ë¡œ ì¤„ì„ (í¬ê·€ í´ë˜ìŠ¤ í•™ìŠµ ê°œì„ )
    'learning_rate': 1e-5,  # ì•ˆì •ì ì¸ í•™ìŠµë¥ 
    'num_epochs': 25,     # 20 â†’ 25ë¡œ ì¦ê°€ (ì‘ì€ ë°°ì¹˜ë¡œ ì¸í•œ ë³´ìƒ)
    'n_folds': 5,      # k_folds â†’ n_foldsë¡œ ë³€ê²½
    'patience': 12,    # 10 â†’ 12ë¡œ ì¦ê°€ (ë” ë§ì€ ì¸ë‚´ì‹¬)
    'dropout_rate': 0.4,  # ì •ê·œí™” ê°•í™”
    'feature_weights': {
        'feat_ending': 1.0,
        'feat_strat_cnt': 2.0,
        'feat_command': 3.5,
        'feat_attack': 4.0,
        'feat_power': 1.5,
        'feat_distance': 1.5,
        'feat_indirect': 2.0
    },
    'manual_data_path': './data/manual_labels_processed.csv',  # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©
    'tydip_data_path': './data/ko_test.csv',  # TyDiP ë°ì´í„° ì¶”ê°€
    'save_dir': './results',
    'seed': 42,
    'use_focal_loss': True,
    'focal_alpha': 5,      # 4 â†’ 5ë¡œ ì¦ê°€ (ë” ê°•í•œ Focal Loss)
    'focal_gamma': 6,      # 5 â†’ 6ë¡œ ì¦ê°€ (ë” ê°•í•œ ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘)
    'scheduler_type': 'cosine',  # Cosine Annealing
    'warmup_ratio': 0.1,       # 0.15 â†’ 0.1ë¡œ ì¤„ì„ (ì‘ì€ ë°°ì¹˜ì— ë§ì¶¤)
    'weight_decay': 0.01,      # 0.02 â†’ 0.01ë¡œ ì¤„ì„ (ì‘ì€ ë°°ì¹˜ë¡œ ì¸í•œ ì¡°ì •)
    'normalize_scores': True,  # ìŠ¤ì½”ì–´ ì •ê·œí™” ì¶”ê°€
    'use_augmentation': True,
    'augmentation_ratio': 0.3,
    'accumulation_steps': 2    # ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì ìœ¼ë¡œ íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸° 16 í™•ë³´
}

# ì—…ë°ì´íŠ¸ëœ í´ë˜ìŠ¤ ìˆ˜ (í´ë˜ìŠ¤ 3 ë³‘í•© í›„)
FEATURE_CONFIGS = {
    'feat_ending': 3,      # 0, 1, 2 (ì›ë˜ 3ì´ 2ë¡œ ë³‘í•©)
    'feat_strat_cnt': 3,   # 0, 1, 2 (ë³€í™” ì—†ìŒ)
    'feat_command': 3,     # 0, 1, 2 (ì›ë˜ 3ì´ 2ë¡œ ë³‘í•©)
    'feat_attack': 3,      # 0, 1, 2 (ì›ë˜ 3ì´ 2ë¡œ ë³‘í•©)
    'feat_power': 3,       # 0, 1, 2 (ì›ë˜ 3ì´ 2ë¡œ ë³‘í•©)
    'feat_distance': 3,    # 0, 1, 2 (ì›ë˜ 3ì´ 2ë¡œ ë³‘í•©)
    'feat_indirect': 3     # 0, 1, 2 (ë³€í™” ì—†ìŒ)
}

if __name__ == "__main__":
    trainer = MultitaskTrainer(config)
    trainer.load_data()
    trainer.run_kfold_training() 